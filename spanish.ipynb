{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "888df6d4-a41a-444a-9622-243929a426cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdf79b8-cafb-496d-9273-df81750ae16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:17:35.957787: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-04 01:17:36.006044: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-04 01:17:36.006729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 01:17:36.824912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#NLTK\n",
    "import nltk\n",
    "from nltk import word_tokenize, WordPunctTokenizer, regexp_tokenize\n",
    "from nltk import word_tokenize, WordPunctTokenizer, regexp_tokenize\n",
    "\n",
    "#Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Keras\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446588d0-3e43-42f9-8e90-dec7ff24a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yes_es = pd.read_json('training/EXIST2023_training.json')\n",
    "train_yes_es=train_yes_es.transpose()\n",
    "train_yes_es=train_yes_es.loc[train_yes_es['lang'].apply(lambda x:x=='es')]\n",
    "train_yes_es=train_yes_es.loc[train_yes_es['labels_task1'].apply(lambda x:x.count('YES')>3)]\n",
    "train_yes_es['label1']='YES'\n",
    "\n",
    "#NO\n",
    "\n",
    "train_no_es = pd.read_json('training/EXIST2023_training.json')\n",
    "train_no_es=train_no_es.transpose()\n",
    "train_no_es=train_no_es.loc[train_no_es['lang'].apply(lambda x:x=='es')]\n",
    "train_no_es=train_no_es.loc[train_no_es['labels_task1'].apply(lambda x:x.count('NO')>3)]\n",
    "train_no_es['label1']='NO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d63b61f-a4da-4d3a-9fb5-14df26d92e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_yes_es = pd.read_json('dev/EXIST2023_dev.json')\n",
    "validation_yes_es=validation_yes_es.transpose()\n",
    "validation_yes_es=validation_yes_es.loc[validation_yes_es['lang'].apply(lambda x:x=='es')]\n",
    "validation_yes_es=validation_yes_es.loc[validation_yes_es['labels_task1'].apply(lambda x:x.count('YES')>3)]\n",
    "validation_yes_es['label1']='YES'\n",
    "\n",
    "#NO\n",
    "\n",
    "validation_no_es = pd.read_json('dev/EXIST2023_dev.json')\n",
    "validation_no_es=validation_no_es.transpose()\n",
    "validation_no_es=validation_no_es.loc[validation_no_es['lang'].apply(lambda x:x=='es')]\n",
    "validation_no_es=validation_no_es.loc[validation_no_es['labels_task1'].apply(lambda x:x.count('NO')>3)]\n",
    "validation_no_es['label1']='NO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5f160df-2978-45b4-aa39-477fc8ee244f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>number_annotators</th>\n",
       "      <th>annotators</th>\n",
       "      <th>gender_annotators</th>\n",
       "      <th>age_annotators</th>\n",
       "      <th>labels_task1</th>\n",
       "      <th>labels_task2</th>\n",
       "      <th>labels_task3</th>\n",
       "      <th>split</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300002</td>\n",
       "      <td>es</td>\n",
       "      <td>@anacaotica88 @MordorLivin No me acuerdo de lo...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_731, Annotator_732, Annotator_315, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[YES, YES, NO, YES, YES, YES]</td>\n",
       "      <td>[JUDGEMENTAL, REPORTED, -, JUDGEMENTAL, JUDGEM...</td>\n",
       "      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300004</td>\n",
       "      <td>es</td>\n",
       "      <td>Also mientras les decia eso la señalaba y deci...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_259, Annotator_739, Annotator_291, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[NO, YES, YES, YES, YES, YES]</td>\n",
       "      <td>[-, REPORTED, REPORTED, REPORTED, JUDGEMENTAL,...</td>\n",
       "      <td>[[-], [SEXUAL-VIOLENCE], [SEXUAL-VIOLENCE], [S...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300007</td>\n",
       "      <td>es</td>\n",
       "      <td>@DavidGR18 @pppbernat @abc_es @agarzon @IreneM...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_731, Annotator_732, Annotator_315, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[YES, YES, NO, YES, YES, YES]</td>\n",
       "      <td>[DIRECT, DIRECT, -, DIRECT, JUDGEMENTAL, REPOR...</td>\n",
       "      <td>[[IDEOLOGICAL-INEQUALITY, SEXUAL-VIOLENCE, MIS...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300008</td>\n",
       "      <td>es</td>\n",
       "      <td>@DavidArranzVox @AnabelAlonso_of Uyyy a q huel...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_742, Annotator_743, Annotator_195, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[YES, YES, NO, YES, YES, YES]</td>\n",
       "      <td>[JUDGEMENTAL, JUDGEMENTAL, -, REPORTED, JUDGEM...</td>\n",
       "      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300010</td>\n",
       "      <td>es</td>\n",
       "      <td>@kokreto84 @Play87834898 @venusoncrack Me gust...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_744, Annotator_745, Annotator_746, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[YES, YES, YES, YES, YES, YES]</td>\n",
       "      <td>[DIRECT, REPORTED, DIRECT, JUDGEMENTAL, DIRECT...</td>\n",
       "      <td>[[MISOGYNY-NON-SEXUAL-VIOLENCE], [STEREOTYPING...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>300534</td>\n",
       "      <td>es</td>\n",
       "      <td>El Gobernador @samuel_garcias  se da el lujo d...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_726, Annotator_727, Annotator_357, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[NO, YES, YES, NO, NO, NO]</td>\n",
       "      <td>[-, REPORTED, JUDGEMENTAL, -, -, -]</td>\n",
       "      <td>[[-], [IDEOLOGICAL-INEQUALITY], [STEREOTYPING-...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>300538</td>\n",
       "      <td>es</td>\n",
       "      <td>Violencia simbólica también es un Presidente q...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_750, Annotator_751, Annotator_189, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[NO, NO, NO, NO, NO, NO]</td>\n",
       "      <td>[-, -, -, -, -, -]</td>\n",
       "      <td>[[-], [-], [-], [-], [-], [-]]</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>300539</td>\n",
       "      <td>es</td>\n",
       "      <td>En el #podcast Un día de libros 67: Violencia ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_754, Annotator_320, Annotator_123, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[NO, YES, NO, NO, NO, NO]</td>\n",
       "      <td>[-, REPORTED, -, -, -, -]</td>\n",
       "      <td>[[-], [MISOGYNY-NON-SEXUAL-VIOLENCE], [-], [-]...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>300540</td>\n",
       "      <td>es</td>\n",
       "      <td>Top story: NBA tiene menos actos de violencia ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_259, Annotator_739, Annotator_291, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[NO, NO, NO, NO, YES, NO]</td>\n",
       "      <td>[-, -, -, -, JUDGEMENTAL, -]</td>\n",
       "      <td>[[-], [-], [-], [-], [MISOGYNY-NON-SEXUAL-VIOL...</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>300542</td>\n",
       "      <td>es</td>\n",
       "      <td>@ulisesjaitt Si violó? Estuvo preso, poco tiem...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_754, Annotator_320, Annotator_123, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n",
       "      <td>[NO, YES, NO, NO, NO, NO]</td>\n",
       "      <td>[-, JUDGEMENTAL, -, -, -, -]</td>\n",
       "      <td>[[-], [SEXUAL-VIOLENCE], [-], [-], [-], [-]]</td>\n",
       "      <td>DEV_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_EXIST lang                                              tweet  \\\n",
       "0     300002   es  @anacaotica88 @MordorLivin No me acuerdo de lo...   \n",
       "1     300004   es  Also mientras les decia eso la señalaba y deci...   \n",
       "2     300007   es  @DavidGR18 @pppbernat @abc_es @agarzon @IreneM...   \n",
       "3     300008   es  @DavidArranzVox @AnabelAlonso_of Uyyy a q huel...   \n",
       "4     300010   es  @kokreto84 @Play87834898 @venusoncrack Me gust...   \n",
       "..       ...  ...                                                ...   \n",
       "485   300534   es  El Gobernador @samuel_garcias  se da el lujo d...   \n",
       "486   300538   es  Violencia simbólica también es un Presidente q...   \n",
       "487   300539   es  En el #podcast Un día de libros 67: Violencia ...   \n",
       "488   300540   es  Top story: NBA tiene menos actos de violencia ...   \n",
       "489   300542   es  @ulisesjaitt Si violó? Estuvo preso, poco tiem...   \n",
       "\n",
       "    number_annotators                                         annotators  \\\n",
       "0                   6  [Annotator_731, Annotator_732, Annotator_315, ...   \n",
       "1                   6  [Annotator_259, Annotator_739, Annotator_291, ...   \n",
       "2                   6  [Annotator_731, Annotator_732, Annotator_315, ...   \n",
       "3                   6  [Annotator_742, Annotator_743, Annotator_195, ...   \n",
       "4                   6  [Annotator_744, Annotator_745, Annotator_746, ...   \n",
       "..                ...                                                ...   \n",
       "485                 6  [Annotator_726, Annotator_727, Annotator_357, ...   \n",
       "486                 6  [Annotator_750, Annotator_751, Annotator_189, ...   \n",
       "487                 6  [Annotator_754, Annotator_320, Annotator_123, ...   \n",
       "488                 6  [Annotator_259, Annotator_739, Annotator_291, ...   \n",
       "489                 6  [Annotator_754, Annotator_320, Annotator_123, ...   \n",
       "\n",
       "      gender_annotators                          age_annotators  \\\n",
       "0    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "1    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "2    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "3    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "4    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "..                  ...                                     ...   \n",
       "485  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "486  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "487  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "488  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "489  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n",
       "\n",
       "                       labels_task1  \\\n",
       "0     [YES, YES, NO, YES, YES, YES]   \n",
       "1     [NO, YES, YES, YES, YES, YES]   \n",
       "2     [YES, YES, NO, YES, YES, YES]   \n",
       "3     [YES, YES, NO, YES, YES, YES]   \n",
       "4    [YES, YES, YES, YES, YES, YES]   \n",
       "..                              ...   \n",
       "485      [NO, YES, YES, NO, NO, NO]   \n",
       "486        [NO, NO, NO, NO, NO, NO]   \n",
       "487       [NO, YES, NO, NO, NO, NO]   \n",
       "488       [NO, NO, NO, NO, YES, NO]   \n",
       "489       [NO, YES, NO, NO, NO, NO]   \n",
       "\n",
       "                                          labels_task2  \\\n",
       "0    [JUDGEMENTAL, REPORTED, -, JUDGEMENTAL, JUDGEM...   \n",
       "1    [-, REPORTED, REPORTED, REPORTED, JUDGEMENTAL,...   \n",
       "2    [DIRECT, DIRECT, -, DIRECT, JUDGEMENTAL, REPOR...   \n",
       "3    [JUDGEMENTAL, JUDGEMENTAL, -, REPORTED, JUDGEM...   \n",
       "4    [DIRECT, REPORTED, DIRECT, JUDGEMENTAL, DIRECT...   \n",
       "..                                                 ...   \n",
       "485                [-, REPORTED, JUDGEMENTAL, -, -, -]   \n",
       "486                                 [-, -, -, -, -, -]   \n",
       "487                          [-, REPORTED, -, -, -, -]   \n",
       "488                       [-, -, -, -, JUDGEMENTAL, -]   \n",
       "489                       [-, JUDGEMENTAL, -, -, -, -]   \n",
       "\n",
       "                                          labels_task3   split label1  \n",
       "0    [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  DEV_ES    YES  \n",
       "1    [[-], [SEXUAL-VIOLENCE], [SEXUAL-VIOLENCE], [S...  DEV_ES    YES  \n",
       "2    [[IDEOLOGICAL-INEQUALITY, SEXUAL-VIOLENCE, MIS...  DEV_ES    YES  \n",
       "3    [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  DEV_ES    YES  \n",
       "4    [[MISOGYNY-NON-SEXUAL-VIOLENCE], [STEREOTYPING...  DEV_ES    YES  \n",
       "..                                                 ...     ...    ...  \n",
       "485  [[-], [IDEOLOGICAL-INEQUALITY], [STEREOTYPING-...  DEV_ES     NO  \n",
       "486                     [[-], [-], [-], [-], [-], [-]]  DEV_ES     NO  \n",
       "487  [[-], [MISOGYNY-NON-SEXUAL-VIOLENCE], [-], [-]...  DEV_ES     NO  \n",
       "488  [[-], [-], [-], [-], [MISOGYNY-NON-SEXUAL-VIOL...  DEV_ES     NO  \n",
       "489       [[-], [SEXUAL-VIOLENCE], [-], [-], [-], [-]]  DEV_ES     NO  \n",
       "\n",
       "[490 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [validation_yes_es, validation_no_es]\n",
    "validation = pd.concat(frames)\n",
    "validation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c96838-715e-4830-a73a-fd39d30354a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>number_annotators</th>\n",
       "      <th>annotators</th>\n",
       "      <th>gender_annotators</th>\n",
       "      <th>age_annotators</th>\n",
       "      <th>labels_task1</th>\n",
       "      <th>labels_task2</th>\n",
       "      <th>labels_task3</th>\n",
       "      <th>split</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>es</td>\n",
       "      <td>@TheChiflis Ignora al otro, es un capullo.El p...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, YES, NO, YES, YES, YES]</td>\n",
       "      <td>[REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...</td>\n",
       "      <td>[[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>es</td>\n",
       "      <td>@novadragon21 @icep4ck @TvDannyZ Entonces como...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_19, Annotator_20, Annotator_21, Ann...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, NO, YES, NO, YES, YES]</td>\n",
       "      <td>[REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...</td>\n",
       "      <td>[[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100008</td>\n",
       "      <td>es</td>\n",
       "      <td>@BestKabest Esta gringa sigue llorando por el ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_25, Annotator_26, Annotator_27, Ann...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, YES, YES, YES, YES, YES]</td>\n",
       "      <td>[DIRECT, DIRECT, DIRECT, JUDGEMENTAL, DIRECT, ...</td>\n",
       "      <td>[[IDEOLOGICAL-INEQUALITY], [STEREOTYPING-DOMIN...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>es</td>\n",
       "      <td>@ShahidForChange @TeamPelosi Quiet, sexist ^%$...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_109, Annotator_110, Annotator_111, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, NO, NO, YES, YES, YES]</td>\n",
       "      <td>[JUDGEMENTAL, -, -, DIRECT, DIRECT, DIRECT]</td>\n",
       "      <td>[[STEREOTYPING-DOMINANCE], [-], [-], [IDEOLOGI...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100036</td>\n",
       "      <td>es</td>\n",
       "      <td>@Harassed_girl loca d mierda en k momento</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_115, Annotator_116, Annotator_117, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, YES, YES, YES, YES, NO]</td>\n",
       "      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, -]</td>\n",
       "      <td>[[STEREOTYPING-DOMINANCE, SEXUAL-VIOLENCE], [M...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>103616</td>\n",
       "      <td>es</td>\n",
       "      <td>@petrogustavo Doctor ... repito, los niños que...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_139, Annotator_140, Annotator_141, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[NO, NO, YES, NO, YES, NO]</td>\n",
       "      <td>[-, -, REPORTED, -, DIRECT, -]</td>\n",
       "      <td>[[-], [-], [SEXUAL-VIOLENCE], [-], [IDEOLOGICA...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>103619</td>\n",
       "      <td>es</td>\n",
       "      <td>La Argentina explotada por todos lados, pero p...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_313, Annotator_314, Annotator_315, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[NO, NO, NO, NO, NO, NO]</td>\n",
       "      <td>[-, -, -, -, -, -]</td>\n",
       "      <td>[[-], [-], [-], [-], [-], [-]]</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>103620</td>\n",
       "      <td>es</td>\n",
       "      <td>Hoy con testigos el Presidente López violó la ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_229, Annotator_230, Annotator_231, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[NO, NO, NO, NO, NO, NO]</td>\n",
       "      <td>[-, -, -, -, -, -]</td>\n",
       "      <td>[[-], [-], [-], [-], [-], [-]]</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>103639</td>\n",
       "      <td>es</td>\n",
       "      <td>cahcake ya casi queda poco para el años zorra ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_211, Annotator_212, Annotator_213, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[NO, YES, YES, NO, NO, NO]</td>\n",
       "      <td>[-, DIRECT, JUDGEMENTAL, -, -, -]</td>\n",
       "      <td>[[-], [MISOGYNY-NON-SEXUAL-VIOLENCE], [OBJECTI...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>103651</td>\n",
       "      <td>es</td>\n",
       "      <td>@Hernandez1976 @freddyvasquez Dejen de pensar ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_253, Annotator_254, Annotator_255, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[NO, YES, NO, NO, YES, NO]</td>\n",
       "      <td>[-, DIRECT, -, -, DIRECT, -]</td>\n",
       "      <td>[[-], [OBJECTIFICATION], [-], [-], [OBJECTIFIC...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3194 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_EXIST lang                                              tweet  \\\n",
       "0      100001   es  @TheChiflis Ignora al otro, es un capullo.El p...   \n",
       "1      100005   es  @novadragon21 @icep4ck @TvDannyZ Entonces como...   \n",
       "2      100008   es  @BestKabest Esta gringa sigue llorando por el ...   \n",
       "3      100028   es  @ShahidForChange @TeamPelosi Quiet, sexist ^%$...   \n",
       "4      100036   es          @Harassed_girl loca d mierda en k momento   \n",
       "...       ...  ...                                                ...   \n",
       "3189   103616   es  @petrogustavo Doctor ... repito, los niños que...   \n",
       "3190   103619   es  La Argentina explotada por todos lados, pero p...   \n",
       "3191   103620   es  Hoy con testigos el Presidente López violó la ...   \n",
       "3192   103639   es  cahcake ya casi queda poco para el años zorra ...   \n",
       "3193   103651   es  @Hernandez1976 @freddyvasquez Dejen de pensar ...   \n",
       "\n",
       "     number_annotators                                         annotators  \\\n",
       "0                    6  [Annotator_1, Annotator_2, Annotator_3, Annota...   \n",
       "1                    6  [Annotator_19, Annotator_20, Annotator_21, Ann...   \n",
       "2                    6  [Annotator_25, Annotator_26, Annotator_27, Ann...   \n",
       "3                    6  [Annotator_109, Annotator_110, Annotator_111, ...   \n",
       "4                    6  [Annotator_115, Annotator_116, Annotator_117, ...   \n",
       "...                ...                                                ...   \n",
       "3189                 6  [Annotator_139, Annotator_140, Annotator_141, ...   \n",
       "3190                 6  [Annotator_313, Annotator_314, Annotator_315, ...   \n",
       "3191                 6  [Annotator_229, Annotator_230, Annotator_231, ...   \n",
       "3192                 6  [Annotator_211, Annotator_212, Annotator_213, ...   \n",
       "3193                 6  [Annotator_253, Annotator_254, Annotator_255, ...   \n",
       "\n",
       "       gender_annotators                          age_annotators  \\\n",
       "0     [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "1     [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "2     [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "3     [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "4     [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "...                  ...                                     ...   \n",
       "3189  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "3190  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "3191  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "3192  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "3193  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "\n",
       "                        labels_task1  \\\n",
       "0      [YES, YES, NO, YES, YES, YES]   \n",
       "1       [YES, NO, YES, NO, YES, YES]   \n",
       "2     [YES, YES, YES, YES, YES, YES]   \n",
       "3       [YES, NO, NO, YES, YES, YES]   \n",
       "4      [YES, YES, YES, YES, YES, NO]   \n",
       "...                              ...   \n",
       "3189      [NO, NO, YES, NO, YES, NO]   \n",
       "3190        [NO, NO, NO, NO, NO, NO]   \n",
       "3191        [NO, NO, NO, NO, NO, NO]   \n",
       "3192      [NO, YES, YES, NO, NO, NO]   \n",
       "3193      [NO, YES, NO, NO, YES, NO]   \n",
       "\n",
       "                                           labels_task2  \\\n",
       "0     [REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...   \n",
       "1     [REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...   \n",
       "2     [DIRECT, DIRECT, DIRECT, JUDGEMENTAL, DIRECT, ...   \n",
       "3           [JUDGEMENTAL, -, -, DIRECT, DIRECT, DIRECT]   \n",
       "4           [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, -]   \n",
       "...                                                 ...   \n",
       "3189                     [-, -, REPORTED, -, DIRECT, -]   \n",
       "3190                                 [-, -, -, -, -, -]   \n",
       "3191                                 [-, -, -, -, -, -]   \n",
       "3192                  [-, DIRECT, JUDGEMENTAL, -, -, -]   \n",
       "3193                       [-, DIRECT, -, -, DIRECT, -]   \n",
       "\n",
       "                                           labels_task3     split label1  \n",
       "0     [[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...  TRAIN_ES    YES  \n",
       "1     [[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...  TRAIN_ES    YES  \n",
       "2     [[IDEOLOGICAL-INEQUALITY], [STEREOTYPING-DOMIN...  TRAIN_ES    YES  \n",
       "3     [[STEREOTYPING-DOMINANCE], [-], [-], [IDEOLOGI...  TRAIN_ES    YES  \n",
       "4     [[STEREOTYPING-DOMINANCE, SEXUAL-VIOLENCE], [M...  TRAIN_ES    YES  \n",
       "...                                                 ...       ...    ...  \n",
       "3189  [[-], [-], [SEXUAL-VIOLENCE], [-], [IDEOLOGICA...  TRAIN_ES     NO  \n",
       "3190                     [[-], [-], [-], [-], [-], [-]]  TRAIN_ES     NO  \n",
       "3191                     [[-], [-], [-], [-], [-], [-]]  TRAIN_ES     NO  \n",
       "3192  [[-], [MISOGYNY-NON-SEXUAL-VIOLENCE], [OBJECTI...  TRAIN_ES     NO  \n",
       "3193  [[-], [OBJECTIFICATION], [-], [-], [OBJECTIFIC...  TRAIN_ES     NO  \n",
       "\n",
       "[3194 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [train_yes_es, train_no_es]\n",
    "train = pd.concat(frames)\n",
    "train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ff70b8-1bde-4164-97da-2bac98580b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hash_regex = re.compile(r\"#(\\w+)\")\n",
    "hstgs = [] # To store the hashtags so we can exclude them from some parts of the analysis\n",
    "def hash_repl(match):\n",
    "    _ = '__HASH_'+match.group(1).upper()\n",
    "    hstgs.append(_)\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f83f9f-5ab5-4ffa-a84b-98a5f46d5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_regex = re.compile(r\"@(\\w+)\")\n",
    "usr_names = [] # To store the user names so we can exclude them from some parts of the analysis\n",
    "def user_repl(match):\n",
    "    _ = '__user_'+match.group(1).upper()\n",
    "    usr_names.append(_)\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54cc094b-1626-4cf7-8822-64287e8029cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = re.compile(r\"(http|https|ftp)://[a-zA-Z0-9\\./]+\")\n",
    "def url_repl(match):\n",
    "    return '__URL_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d0a701-91df-4920-9dde-c0eb5d665359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating words like hurrrryyyyyy\n",
    "rpt_regex = re.compile(r\"(.)\\1{1,}\", re.IGNORECASE);\n",
    "def rpt_repl(match):\n",
    "    return match.group(1)+match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab24dbc-451e-40ee-97d1-769b019aa2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting by word boundaries\n",
    "word_bound_regex = re.compile(r\"\\W+\")\n",
    "\n",
    "# Punctuations\n",
    "punctuations = \\\n",
    "\t[\t#('',\t\t['.', ] )\t,\\\n",
    "\t\t#('',\t\t[',', ] )\t,\\\n",
    "\t\t#('',\t\t['\\'', '\\\"', ] )\t,\\\n",
    "\t\t('__PUNC_EXCL',\t\t['!', '¡', ] )\t,\\\n",
    "\t\t('__PUNC_QUES',\t\t['?', '¿', ] )\t,\\\n",
    "\t\t('__PUNC_ELLP',\t\t['...', '…', ] )\t,\\\n",
    "\t]\n",
    "\n",
    "#For punctuation replacement\n",
    "def punctuations_repl(match):\n",
    "\ttext = match.group(0)\n",
    "\trepl = []\n",
    "\tfor (key, parr) in punctuations :\n",
    "\t\tfor punc in parr :\n",
    "\t\t\tif punc in text:\n",
    "\t\t\t\trepl.append(key)\n",
    "\tif( len(repl)>0 ) :\n",
    "\t\treturn ' '+' '.join(repl)+' '\n",
    "\telse :\n",
    "\t\treturn ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c1f1e4-ea63-4a41-99d2-dfe4b6ee86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e28fcc-769b-41de-a749-41c1de30e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sb_stem(text, only_first=0):\n",
    "    text = [word if(word[0:2]=='__') else word.lower() for word in text.split() if ((len(word) >= 3) or (word in ['no','si', 'sí', 'ni']))] #   If we are doing negation analysis, maybe is a better idea to keep the small words (like 'no')\n",
    "    text = [stemmer.stem(w) if w[0:2]!='__' else w for w in text ]\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdba3594-c4f4-4a7c-810f-6d261466113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAll(text):\n",
    "    text = re.sub( hash_regex, hash_repl, text )\n",
    "    #text = re.sub( user_regex, user_repl, text)\n",
    "    text = re.sub( url_regex, url_repl, text )\n",
    "    \n",
    "    text = text.replace('\\'','')\n",
    "    \n",
    "    text = re.sub( word_bound_regex , punctuations_repl, text )\n",
    "    text = re.sub( rpt_regex, rpt_repl, text )\n",
    "    \n",
    "    text = sb_stem(text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c828b58d-402a-47a4-bab8-bbb46786110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed_tweet'] = train.tweet.apply(processAll)\n",
    "validation['processed_tweet'] = validation.tweet.apply(processAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76f8df-6cfd-45cc-8309-a48b32120f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b477e96-3382-4cda-ae81-87e680ce0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>number_annotators</th>\n",
       "      <th>annotators</th>\n",
       "      <th>gender_annotators</th>\n",
       "      <th>age_annotators</th>\n",
       "      <th>labels_task1</th>\n",
       "      <th>labels_task2</th>\n",
       "      <th>labels_task3</th>\n",
       "      <th>split</th>\n",
       "      <th>label1</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>100001</td>\n",
       "      <td>es</td>\n",
       "      <td>@TheChiflis Ignora al otro, es un capullo.El p...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, YES, NO, YES, YES, YES]</td>\n",
       "      <td>[REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...</td>\n",
       "      <td>[[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "      <td>[thechiflis, ignor, otro, capull, problem, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>100005</td>\n",
       "      <td>es</td>\n",
       "      <td>@novadragon21 @icep4ck @TvDannyZ Entonces como...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_19, Annotator_20, Annotator_21, Ann...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, NO, YES, NO, YES, YES]</td>\n",
       "      <td>[REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...</td>\n",
       "      <td>[[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "      <td>[novadragon21, icep4ck, tvdannyz, entonc, com,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100008</th>\n",
       "      <td>100008</td>\n",
       "      <td>es</td>\n",
       "      <td>@BestKabest Esta gringa sigue llorando por el ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_25, Annotator_26, Annotator_27, Ann...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, YES, YES, YES, YES, YES]</td>\n",
       "      <td>[DIRECT, DIRECT, DIRECT, JUDGEMENTAL, DIRECT, ...</td>\n",
       "      <td>[[IDEOLOGICAL-INEQUALITY], [STEREOTYPING-DOMIN...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "      <td>[bestkabest, esta, gring, sig, llor, por, game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100028</th>\n",
       "      <td>100028</td>\n",
       "      <td>es</td>\n",
       "      <td>@ShahidForChange @TeamPelosi Quiet, sexist ^%$...</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_109, Annotator_110, Annotator_111, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, NO, NO, YES, YES, YES]</td>\n",
       "      <td>[JUDGEMENTAL, -, -, DIRECT, DIRECT, DIRECT]</td>\n",
       "      <td>[[STEREOTYPING-DOMINANCE], [-], [-], [IDEOLOGI...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "      <td>[shahidforchang, teampelosi, quiet, sexist, __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100036</th>\n",
       "      <td>100036</td>\n",
       "      <td>es</td>\n",
       "      <td>@Harassed_girl loca d mierda en k momento</td>\n",
       "      <td>6</td>\n",
       "      <td>[Annotator_115, Annotator_116, Annotator_117, ...</td>\n",
       "      <td>[F, F, F, M, M, M]</td>\n",
       "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
       "      <td>[YES, YES, YES, YES, YES, NO]</td>\n",
       "      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, -]</td>\n",
       "      <td>[[STEREOTYPING-DOMINANCE, SEXUAL-VIOLENCE], [M...</td>\n",
       "      <td>TRAIN_ES</td>\n",
       "      <td>YES</td>\n",
       "      <td>[harassed_girl, loc, mierd, moment]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_EXIST lang                                              tweet  \\\n",
       "100001   100001   es  @TheChiflis Ignora al otro, es un capullo.El p...   \n",
       "100005   100005   es  @novadragon21 @icep4ck @TvDannyZ Entonces como...   \n",
       "100008   100008   es  @BestKabest Esta gringa sigue llorando por el ...   \n",
       "100028   100028   es  @ShahidForChange @TeamPelosi Quiet, sexist ^%$...   \n",
       "100036   100036   es          @Harassed_girl loca d mierda en k momento   \n",
       "\n",
       "       number_annotators                                         annotators  \\\n",
       "100001                 6  [Annotator_1, Annotator_2, Annotator_3, Annota...   \n",
       "100005                 6  [Annotator_19, Annotator_20, Annotator_21, Ann...   \n",
       "100008                 6  [Annotator_25, Annotator_26, Annotator_27, Ann...   \n",
       "100028                 6  [Annotator_109, Annotator_110, Annotator_111, ...   \n",
       "100036                 6  [Annotator_115, Annotator_116, Annotator_117, ...   \n",
       "\n",
       "         gender_annotators                          age_annotators  \\\n",
       "100001  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "100005  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "100008  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "100028  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "100036  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
       "\n",
       "                          labels_task1  \\\n",
       "100001   [YES, YES, NO, YES, YES, YES]   \n",
       "100005    [YES, NO, YES, NO, YES, YES]   \n",
       "100008  [YES, YES, YES, YES, YES, YES]   \n",
       "100028    [YES, NO, NO, YES, YES, YES]   \n",
       "100036   [YES, YES, YES, YES, YES, NO]   \n",
       "\n",
       "                                             labels_task2  \\\n",
       "100001  [REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...   \n",
       "100005  [REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...   \n",
       "100008  [DIRECT, DIRECT, DIRECT, JUDGEMENTAL, DIRECT, ...   \n",
       "100028        [JUDGEMENTAL, -, -, DIRECT, DIRECT, DIRECT]   \n",
       "100036        [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, -]   \n",
       "\n",
       "                                             labels_task3     split label1  \\\n",
       "100001  [[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...  TRAIN_ES    YES   \n",
       "100005  [[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...  TRAIN_ES    YES   \n",
       "100008  [[IDEOLOGICAL-INEQUALITY], [STEREOTYPING-DOMIN...  TRAIN_ES    YES   \n",
       "100028  [[STEREOTYPING-DOMINANCE], [-], [-], [IDEOLOGI...  TRAIN_ES    YES   \n",
       "100036  [[STEREOTYPING-DOMINANCE, SEXUAL-VIOLENCE], [M...  TRAIN_ES    YES   \n",
       "\n",
       "                                          processed_tweet  \n",
       "100001  [thechiflis, ignor, otro, capull, problem, con...  \n",
       "100005  [novadragon21, icep4ck, tvdannyz, entonc, com,...  \n",
       "100008  [bestkabest, esta, gring, sig, llor, por, game...  \n",
       "100028  [shahidforchang, teampelosi, quiet, sexist, __...  \n",
       "100036                [harassed_girl, loc, mierd, moment]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b8229af-5964-4870-a770-e39561aa67a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[thechiflis, ignor, otro, capull, problem, con...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[novadragon21, icep4ck, tvdannyz, entonc, com,...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bestkabest, esta, gring, sig, llor, por, game...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[shahidforchang, teampelosi, quiet, sexist, __...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[harassed_girl, loc, mierd, moment]</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>[petrogustav, doctor, __PUNC_ELLP, repit, los,...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>[argentin, explot, por, tod, lad, per, pag, de...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>[hoy, con, testig, president, lopez, viol, ley...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>[cahcak, casi, qued, poc, par, años, zorr, sol...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>[hernandez1976, freddyvasquez, dej, pens, rat,...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "0     [thechiflis, ignor, otro, capull, problem, con...   YES\n",
       "1     [novadragon21, icep4ck, tvdannyz, entonc, com,...   YES\n",
       "2     [bestkabest, esta, gring, sig, llor, por, game...   YES\n",
       "3     [shahidforchang, teampelosi, quiet, sexist, __...   YES\n",
       "4                   [harassed_girl, loc, mierd, moment]   YES\n",
       "...                                                 ...   ...\n",
       "3189  [petrogustav, doctor, __PUNC_ELLP, repit, los,...    NO\n",
       "3190  [argentin, explot, por, tod, lad, per, pag, de...    NO\n",
       "3191  [hoy, con, testig, president, lopez, viol, ley...    NO\n",
       "3192  [cahcak, casi, qued, poc, par, años, zorr, sol...    NO\n",
       "3193  [hernandez1976, freddyvasquez, dej, pens, rat,...    NO\n",
       "\n",
       "[3194 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "train_data['tweet'] = train['processed_tweet']\n",
    "train_data['label'] = train['label1']\n",
    "train_data.reset_index(inplace=True, drop = True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e6a3358-b508-4a24-81f0-5d8a56bcf561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[anacaotica88, mordorlivin, acuerd, los, detal...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[also, mientr, les, deci, eso, señal, deci, qu...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[davidgr18, ppbernat, abc_es, agarzon, irenemo...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[davidarranzvox, anabelalonso_of, uyy, huel, _...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[kokreto84, play87834898, venusoncrack, gust, ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>[gobern, samuel_garci, luj, sub, vide, complet...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>[violenci, simbol, tambien, president, que, to...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>[__HASH_PODCAST, dia, libr, violenci, simbol, ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>[top, story, nba, tien, men, actos, violenci, ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>[ulisesjaitt, viol, __PUNC_QUES, estuv, pres, ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet label\n",
       "0    [anacaotica88, mordorlivin, acuerd, los, detal...   YES\n",
       "1    [also, mientr, les, deci, eso, señal, deci, qu...   YES\n",
       "2    [davidgr18, ppbernat, abc_es, agarzon, irenemo...   YES\n",
       "3    [davidarranzvox, anabelalonso_of, uyy, huel, _...   YES\n",
       "4    [kokreto84, play87834898, venusoncrack, gust, ...   YES\n",
       "..                                                 ...   ...\n",
       "485  [gobern, samuel_garci, luj, sub, vide, complet...    NO\n",
       "486  [violenci, simbol, tambien, president, que, to...    NO\n",
       "487  [__HASH_PODCAST, dia, libr, violenci, simbol, ...    NO\n",
       "488  [top, story, nba, tien, men, actos, violenci, ...    NO\n",
       "489  [ulisesjaitt, viol, __PUNC_QUES, estuv, pres, ...    NO\n",
       "\n",
       "[490 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = pd.DataFrame()\n",
    "validation_data['tweet'] = validation['processed_tweet']\n",
    "validation_data['label'] = validation['label1']\n",
    "validation_data.reset_index(inplace=True, drop = True)\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58d3ec08-fd0a-48b9-9fca-d6a20c7fa6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(max(train_data['tweet'].apply(len)))\n",
    "print(max(validation_data['tweet'].apply(len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eacb49e5-72a6-473f-8021-e82a11ea6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfedd40-6b1c-4508-94c6-c4b313f56ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = KeyedVectors.load_word2vec_format('SBW-vectors-300-min5.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cedc258b-2aac-4c4f-bc59-5cfb53546fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tweet(tweet):\n",
    "    vec = []\n",
    "    for word in tweet:\n",
    "        if word in vecs.key_to_index:\n",
    "            vec.append(vecs[word])\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88bf3bd8-f36c-42d2-b45d-aac01251ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet'] = train_data['tweet'].apply(vectorize_tweet)\n",
    "validation_data['tweet'] = validation_data['tweet'].apply(vectorize_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f72fdf2e-7053-4360-9d1f-0c3c6b841d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "43\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3834030-2173-4d5d-9b76-4c39b2ad0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "X_train = list(train_data['tweet'])\n",
    "Y_train = list(train_data['label'])\n",
    "\n",
    "X_test = list(validation_data['tweet'])\n",
    "Y_test = list(validation_data['label'])\n",
    "\n",
    "temp = list(zip(X_train, Y_train))\n",
    "random.shuffle(temp)\n",
    "X_train, Y_train = zip(*temp)\n",
    "X_train = list(X_train)\n",
    "Y_train = list(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "880a2f34-3187-4cbd-9ef9-7e516bf57797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a5de1f2-2d6d-486e-88a6-9d9dacf3632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padto43(x):\n",
    "    if len(x) < 43:\n",
    "        for i in range(43 - len(x)):\n",
    "            x.append([0]*300)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4019fce7-8682-4a07-b288-c85eff9710b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i] = padto43(X_train[i])\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = padto43(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0f48f8b-92c3-4280-a6be-f9a1edaa39d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:29:31.540437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 01:29:31.541803: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = tf.convert_to_tensor(X_train)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a15bcf68-db87-40d4-a99c-69d582df39d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3194   43  300], shape=(3,), dtype=int32)\n",
      "tf.Tensor([490  43 300], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(X_train_tensor))\n",
    "print(tf.shape(X_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0596398-8e47-4ae7-9861-8d95d6c5e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert yes to 1 and no to 0\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i] == 'YES':\n",
    "        Y_train[i] = [1, 0]\n",
    "    else:\n",
    "        Y_train[i] = [0, 1]\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i] == 'YES':\n",
    "        Y_test[i] = [1, 0]\n",
    "    else:\n",
    "        Y_test[i] = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "107288fb-040c-4fe9-a6bc-9224e900a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_train_tensor = tf.convert_to_tensor(Y_train)\n",
    "Y_test_tensor = tf.convert_to_tensor(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5cf3ddd-cbdb-4856-ad6a-3d0ff4323a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 150)               270600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 302       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,902\n",
      "Trainable params: 270,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:31:00.775216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:31:00.776890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:31:00.778114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "MLmodel = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(150),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "MLmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "MLmodel.build(input_shape=(None, 43, 300))\n",
    "MLmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34e37d16-d005-4ee9-8ede-d301e842da8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.5064 - accuracy: 0.7595 - val_loss: 0.6136 - val_accuracy: 0.7000\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.5060 - accuracy: 0.7655 - val_loss: 0.5916 - val_accuracy: 0.6796\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4882 - accuracy: 0.7774 - val_loss: 0.6248 - val_accuracy: 0.6735\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4938 - accuracy: 0.7796 - val_loss: 0.5868 - val_accuracy: 0.7082\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4815 - accuracy: 0.7877 - val_loss: 0.6247 - val_accuracy: 0.6878\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4793 - accuracy: 0.7924 - val_loss: 0.6030 - val_accuracy: 0.6939\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4763 - accuracy: 0.7959 - val_loss: 0.5967 - val_accuracy: 0.6735\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.4668 - accuracy: 0.7971 - val_loss: 0.6391 - val_accuracy: 0.6796\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4415 - accuracy: 0.8147 - val_loss: 0.5885 - val_accuracy: 0.6959\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4233 - accuracy: 0.8284 - val_loss: 0.6273 - val_accuracy: 0.6755\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4499 - accuracy: 0.8134 - val_loss: 0.5980 - val_accuracy: 0.6939\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4173 - accuracy: 0.8338 - val_loss: 0.6150 - val_accuracy: 0.6857\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3997 - accuracy: 0.8475 - val_loss: 0.6520 - val_accuracy: 0.6837\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.4095 - accuracy: 0.8391 - val_loss: 0.6484 - val_accuracy: 0.7082\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3899 - accuracy: 0.8522 - val_loss: 0.6844 - val_accuracy: 0.6878\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3755 - accuracy: 0.8607 - val_loss: 0.7185 - val_accuracy: 0.6816\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3789 - accuracy: 0.8626 - val_loss: 0.6560 - val_accuracy: 0.6878\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3735 - accuracy: 0.8597 - val_loss: 0.6500 - val_accuracy: 0.7204\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3697 - accuracy: 0.8619 - val_loss: 0.7112 - val_accuracy: 0.6857\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3420 - accuracy: 0.8779 - val_loss: 0.7560 - val_accuracy: 0.6755\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.3444 - accuracy: 0.8770 - val_loss: 0.6670 - val_accuracy: 0.7000\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3313 - accuracy: 0.8879 - val_loss: 0.6815 - val_accuracy: 0.7041\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3300 - accuracy: 0.8842 - val_loss: 0.8064 - val_accuracy: 0.6918\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2967 - accuracy: 0.9033 - val_loss: 0.8435 - val_accuracy: 0.6612\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.3015 - accuracy: 0.8989 - val_loss: 0.8482 - val_accuracy: 0.6571\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.2972 - accuracy: 0.9026 - val_loss: 0.7292 - val_accuracy: 0.6878\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2834 - accuracy: 0.9083 - val_loss: 0.7957 - val_accuracy: 0.6959\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2911 - accuracy: 0.9039 - val_loss: 0.8557 - val_accuracy: 0.6673\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2795 - accuracy: 0.9083 - val_loss: 0.7694 - val_accuracy: 0.6857\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2589 - accuracy: 0.9211 - val_loss: 0.7285 - val_accuracy: 0.6939\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2533 - accuracy: 0.9192 - val_loss: 0.8257 - val_accuracy: 0.6735\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2613 - accuracy: 0.9167 - val_loss: 0.8661 - val_accuracy: 0.6776\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2422 - accuracy: 0.9211 - val_loss: 0.8431 - val_accuracy: 0.6837\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2437 - accuracy: 0.9258 - val_loss: 0.8372 - val_accuracy: 0.7000\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2232 - accuracy: 0.9314 - val_loss: 0.9735 - val_accuracy: 0.6735\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2007 - accuracy: 0.9433 - val_loss: 0.8638 - val_accuracy: 0.6959\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.2212 - accuracy: 0.9346 - val_loss: 0.8493 - val_accuracy: 0.6796\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2220 - accuracy: 0.9305 - val_loss: 0.8381 - val_accuracy: 0.7102\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1906 - accuracy: 0.9452 - val_loss: 0.9475 - val_accuracy: 0.6755\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.2015 - accuracy: 0.9427 - val_loss: 0.8400 - val_accuracy: 0.6898\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.1806 - accuracy: 0.9487 - val_loss: 0.9043 - val_accuracy: 0.6918\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1873 - accuracy: 0.9455 - val_loss: 0.8875 - val_accuracy: 0.6878\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1843 - accuracy: 0.9455 - val_loss: 0.9984 - val_accuracy: 0.6796\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1613 - accuracy: 0.9537 - val_loss: 1.1208 - val_accuracy: 0.6755\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1557 - accuracy: 0.9543 - val_loss: 1.2771 - val_accuracy: 0.6510\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1613 - accuracy: 0.9537 - val_loss: 1.3043 - val_accuracy: 0.6755\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1767 - accuracy: 0.9458 - val_loss: 1.1037 - val_accuracy: 0.6796\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1643 - accuracy: 0.9521 - val_loss: 0.9823 - val_accuracy: 0.7000\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1612 - accuracy: 0.9505 - val_loss: 0.9802 - val_accuracy: 0.6837\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.1562 - accuracy: 0.9512 - val_loss: 1.1882 - val_accuracy: 0.6776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36642c1760>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "MLmodel.fit(X_train_tensor, Y_train_tensor, epochs=num_epochs, validation_data=(X_test_tensor, Y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5de6248-5092-46ef-9b21-6b0530841554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:37:22.362058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:37:22.363712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:22.364947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-04 01:37:22.511898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-05-04 01:37:22.562414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 300)              541200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                4816      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 546,050\n",
      "Trainable params: 546,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:37:22.564145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:22.565659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, 43, 300))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48433f6b-afbf-4f61-8572-231991bd38b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:37:40.556548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:37:40.558336: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:40.559643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-04 01:37:40.715135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-05-04 01:37:40.771172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:37:40.772806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:40.774106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-04 01:37:41.323675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-05-04 01:37:42.169261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:37:42.170961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:42.172233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-04 01:37:42.325670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-05-04 01:37:42.381156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:37:42.382844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:42.384215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-04 01:37:42.923034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6736 - accuracy: 0.5814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 01:37:47.885984: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:37:47.887625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:47.888837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-04 01:37:48.036328: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-05-04 01:37:48.088319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-04 01:37:48.089834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-04 01:37:48.091402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 48ms/step - loss: 0.6740 - accuracy: 0.5808 - val_loss: 0.6919 - val_accuracy: 0.5653\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.6508 - accuracy: 0.6218 - val_loss: 0.6243 - val_accuracy: 0.6490\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 0.6186 - accuracy: 0.6528 - val_loss: 0.6210 - val_accuracy: 0.6755\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.6084 - accuracy: 0.6703 - val_loss: 0.6326 - val_accuracy: 0.6449\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.5917 - accuracy: 0.6882 - val_loss: 0.6063 - val_accuracy: 0.6633\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 0.5845 - accuracy: 0.6935 - val_loss: 0.6019 - val_accuracy: 0.6755\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.5693 - accuracy: 0.7120 - val_loss: 0.6234 - val_accuracy: 0.6449\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.5617 - accuracy: 0.7145 - val_loss: 0.6203 - val_accuracy: 0.6714\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.5459 - accuracy: 0.7210 - val_loss: 0.6307 - val_accuracy: 0.6367\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 0.5273 - accuracy: 0.7361 - val_loss: 0.6302 - val_accuracy: 0.6367\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.5157 - accuracy: 0.7411 - val_loss: 0.6219 - val_accuracy: 0.6327\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.5046 - accuracy: 0.7567 - val_loss: 0.6272 - val_accuracy: 0.6694\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.4900 - accuracy: 0.7621 - val_loss: 0.6294 - val_accuracy: 0.6714\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.4812 - accuracy: 0.7758 - val_loss: 0.6106 - val_accuracy: 0.6653\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.4622 - accuracy: 0.7849 - val_loss: 0.6739 - val_accuracy: 0.6918\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.4374 - accuracy: 0.8021 - val_loss: 0.7122 - val_accuracy: 0.6531\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.4221 - accuracy: 0.8087 - val_loss: 0.6707 - val_accuracy: 0.6469\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.4125 - accuracy: 0.8100 - val_loss: 0.6278 - val_accuracy: 0.6816\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.3758 - accuracy: 0.8344 - val_loss: 0.7202 - val_accuracy: 0.6633\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.3494 - accuracy: 0.8491 - val_loss: 0.7452 - val_accuracy: 0.6449\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.3349 - accuracy: 0.8510 - val_loss: 0.7708 - val_accuracy: 0.6367\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.3283 - accuracy: 0.8654 - val_loss: 0.8617 - val_accuracy: 0.6510\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2850 - accuracy: 0.8867 - val_loss: 0.9095 - val_accuracy: 0.6490\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2774 - accuracy: 0.8845 - val_loss: 0.9483 - val_accuracy: 0.6592\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2598 - accuracy: 0.8976 - val_loss: 1.0357 - val_accuracy: 0.6163\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2292 - accuracy: 0.9123 - val_loss: 1.0713 - val_accuracy: 0.6408\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2200 - accuracy: 0.9089 - val_loss: 1.1673 - val_accuracy: 0.6163\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1900 - accuracy: 0.9220 - val_loss: 1.1132 - val_accuracy: 0.6510\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1689 - accuracy: 0.9317 - val_loss: 1.2594 - val_accuracy: 0.6327\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1604 - accuracy: 0.9361 - val_loss: 1.2704 - val_accuracy: 0.6551\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1867 - accuracy: 0.9339 - val_loss: 1.4536 - val_accuracy: 0.6224\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1619 - accuracy: 0.9399 - val_loss: 1.3566 - val_accuracy: 0.6571\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1323 - accuracy: 0.9487 - val_loss: 1.4106 - val_accuracy: 0.6510\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1163 - accuracy: 0.9577 - val_loss: 1.6348 - val_accuracy: 0.6306\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.1007 - accuracy: 0.9602 - val_loss: 1.4678 - val_accuracy: 0.6306\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0872 - accuracy: 0.9684 - val_loss: 1.7824 - val_accuracy: 0.6653\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0644 - accuracy: 0.9781 - val_loss: 2.0784 - val_accuracy: 0.6469\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1099 - accuracy: 0.9587 - val_loss: 1.4351 - val_accuracy: 0.6694\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0996 - accuracy: 0.9652 - val_loss: 1.7390 - val_accuracy: 0.6429\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0777 - accuracy: 0.9693 - val_loss: 1.8487 - val_accuracy: 0.6551\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0596 - accuracy: 0.9778 - val_loss: 1.9131 - val_accuracy: 0.6429\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0663 - accuracy: 0.9734 - val_loss: 2.0133 - val_accuracy: 0.6531\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0839 - accuracy: 0.9684 - val_loss: 1.8434 - val_accuracy: 0.6694\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0564 - accuracy: 0.9803 - val_loss: 2.1943 - val_accuracy: 0.6510\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0501 - accuracy: 0.9806 - val_loss: 2.1962 - val_accuracy: 0.6224\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0781 - accuracy: 0.9706 - val_loss: 1.6352 - val_accuracy: 0.6571\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0511 - accuracy: 0.9818 - val_loss: 2.1682 - val_accuracy: 0.6694\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0611 - accuracy: 0.9793 - val_loss: 1.8269 - val_accuracy: 0.6673\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0398 - accuracy: 0.9856 - val_loss: 2.1752 - val_accuracy: 0.6429\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 2.6657 - val_accuracy: 0.6449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36240e12e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " num_epochs = 50\n",
    "model.fit(X_train_tensor, Y_train_tensor, epochs=num_epochs, validation_data=(X_test_tensor, Y_test_tensor))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
